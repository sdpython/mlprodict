{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Numpy API for ONNX\n",
        "\n",
        "This notebook shows how to write python functions similar functions as numpy offers and get a function which can be converted into ONNX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext mlprodict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## A pipeline with FunctionTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('functiontransformer',\n",
              "                 FunctionTransformer(func=<ufunc 'log'>)),\n",
              "                ('standardscaler', StandardScaler()),\n",
              "                ('logisticregression', LogisticRegression())])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "pipe = make_pipeline(\n",
        "            FunctionTransformer(numpy.log),\n",
        "            StandardScaler(),\n",
        "            LogisticRegression())\n",
        "pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's convert it into ONNX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FunctionTransformer is not supported unless the transform function is None (= identity). You may raise an issue at https://github.com/onnx/sklearn-onnx/issues.\n"
          ]
        }
      ],
      "source": [
        "from mlprodict.onnx_conv import to_onnx\n",
        "try:\n",
        "    onx = to_onnx(pipe, X_train.astype(numpy.float64))\n",
        "except RuntimeError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use ONNX instead of numpy\n",
        "\n",
        "The pipeline cannot be converter because the converter does not know how to convert the function (`numpy.log`) held by `FunctionTransformer` into ONNX. One way to avoid that is to replace it by a function `log` defined with *ONNX* operators and executed with an ONNX runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('functiontransformer',\n",
              "                 FunctionTransformer(func=<mlprodict.npy.onnx_numpy_wrapper.wrapper_onnxnumpy_np object at 0x000001B3233D70D0>)),\n",
              "                ('standardscaler', StandardScaler()),\n",
              "                ('logisticregression', LogisticRegression())])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import mlprodict.npy.numpy_onnx_pyrt as npnxrt\n",
        "\n",
        "pipe = make_pipeline(\n",
        "            FunctionTransformer(npnxrt.log),\n",
        "            StandardScaler(),\n",
        "            LogisticRegression())\n",
        "pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "onx = to_onnx(pipe, X_train.astype(numpy.float64), rewrite_ops=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"M52b03a0cadbf497394e78154c7079ef8-cont\"><div id=\"M52b03a0cadbf497394e78154c7079ef8\" style=\"width:100%;height:100%;\"></div></div>\n",
              "<script>\n",
              "\n",
              "require(['http://www.xavierdupre.fr/js/vizjs/viz.js'], function() { var svgGraph = Viz(\"digraph{\\n  orientation=portrait;\\n  nodesep=0.05;\\n  ranksep=0.25;\\n\\n  X [shape=box color=red label=\\\"X\\ndouble((0, 4))\\\" fontsize=10];\\n\\n  output_label [shape=box color=green label=\\\"output_label\\nint64((0,))\\\" fontsize=10];\\n  output_probability [shape=box color=green label=\\\"output_probability\\n[{int64, {'kind': 'tensor', 'elem': 'double', 'shape': }}]\\\" fontsize=10];\\n\\n\\n  ft_y [shape=box label=\\\"ft_y\\\" fontsize=10];\\n  ft_Log [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Log\\n(ft_Log)\\\" fontsize=10];\\n  X -> ft_Log;\\n  ft_Log -> ft_y;\\n\\n  variable1 [shape=box label=\\\"variable1\\\" fontsize=10];\\n  Scaler [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Scaler\\n(Scaler)\\noffset=[ 1.7466671   1.09394532...\\nscale=[7.50561013 6.94318727 1....\\\" fontsize=10];\\n  ft_y -> Scaler;\\n  Scaler -> variable1;\\n\\n  label [shape=box label=\\\"label\\\" fontsize=10];\\n  probability_tensor [shape=box label=\\\"probability_tensor\\\" fontsize=10];\\n  LinearClassifier [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"LinearClassifier\\n(LinearClassifier)\\nclasslabels_ints=[0 1 2]\\ncoefficients=[-0.9787565   0.88...\\nintercepts=[ 0.28945422  2.1475...\\nmulti_class=1\\npost_transform=b'SOFTMAX'\\\" fontsize=10];\\n  variable1 -> LinearClassifier;\\n  LinearClassifier -> label;\\n  LinearClassifier -> probability_tensor;\\n\\n  probabilities [shape=box label=\\\"probabilities\\\" fontsize=10];\\n  Normalizer [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Normalizer\\n(Normalizer)\\nnorm=b'L1'\\\" fontsize=10];\\n  probability_tensor -> Normalizer;\\n  Normalizer -> probabilities;\\n\\n  Cast [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Cast\\n(Cast)\\nto=7\\\" fontsize=10];\\n  label -> Cast;\\n  Cast -> output_label;\\n\\n  ZipMap [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"ZipMap\\n(ZipMap)\\nclasslabels_int64s=[0 1 2]\\\" fontsize=10];\\n  probabilities -> ZipMap;\\n  ZipMap -> output_probability;\\n}\");\n",
              "document.getElementById('M52b03a0cadbf497394e78154c7079ef8').innerHTML = svgGraph; });\n",
              "\n",
              "</script>"
            ],
            "text/plain": [
              "<jyquickhelper.jspy.render_nb_js_dot.RenderJsDot at 0x1b324cc1a60>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%onnxview onx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The operator `Log` is belongs to the graph. There is some overhead by using this function on small matrices. The gap is much less on big matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.3 \u00b5s \u00b1 295 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit numpy.log(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14.4 \u00b5s \u00b1 2.33 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit npnxrt.log(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## More complex function\n",
        "\n",
        "What about more complex functions? It is a bit more complicated too. The previous syntax does not work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('functiontransformer',\n",
              "                 FunctionTransformer(func=<function custom_fct at 0x000001B32339E430>)),\n",
              "                ('standardscaler', StandardScaler()),\n",
              "                ('logisticregression', LogisticRegression())])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def custom_fct(x):\n",
        "    return npnxrt.log(x + 1)\n",
        "\n",
        "pipe = make_pipeline(\n",
        "            FunctionTransformer(custom_fct),\n",
        "            StandardScaler(),\n",
        "            LogisticRegression())\n",
        "pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FunctionTransformer is not supported unless the transform function is of type <class 'function'> wrapped with onnxnumpy.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    onx = to_onnx(pipe, X_train.astype(numpy.float64), rewrite_ops=True)\n",
        "except TypeError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The syntax is different."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('functiontransformer',\n",
              "                 FunctionTransformer(func=<mlprodict.npy.onnx_numpy_wrapper.onnxnumpy_custom_fct_None_None object at 0x000001B324CF29A0>)),\n",
              "                ('standardscaler', StandardScaler()),\n",
              "                ('logisticregression', LogisticRegression())])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Any\n",
        "from mlprodict.npy import onnxnumpy_default, NDArray\n",
        "import mlprodict.npy.numpy_onnx_impl as npnx\n",
        "\n",
        "@onnxnumpy_default\n",
        "def custom_fct(x: NDArray[(None, None), numpy.float64]) -> NDArray[(None, None), numpy.float64]:\n",
        "    return npnx.log(x + numpy.float64(1))\n",
        "\n",
        "pipe = make_pipeline(\n",
        "            FunctionTransformer(custom_fct),\n",
        "            StandardScaler(),\n",
        "            LogisticRegression())\n",
        "pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"Mb07a422654ee4a4897d015c087ce35a7-cont\"><div id=\"Mb07a422654ee4a4897d015c087ce35a7\" style=\"width:100%;height:100%;\"></div></div>\n",
              "<script>\n",
              "\n",
              "require(['http://www.xavierdupre.fr/js/vizjs/viz.js'], function() { var svgGraph = Viz(\"digraph{\\n  orientation=portrait;\\n  nodesep=0.05;\\n  ranksep=0.25;\\n\\n  X [shape=box color=red label=\\\"X\\ndouble((0, 4))\\\" fontsize=10];\\n\\n  output_label [shape=box color=green label=\\\"output_label\\nint64((0,))\\\" fontsize=10];\\n  output_probability [shape=box color=green label=\\\"output_probability\\n[{int64, {'kind': 'tensor', 'elem': 'double', 'shape': }}]\\\" fontsize=10];\\n\\n  ft_Ad_Addcst [shape=box label=\\\"ft_Ad_Addcst\\nfloat64(())\\n1.0\\\" fontsize=10];\\n\\n  ft_Ad_C0 [shape=box label=\\\"ft_Ad_C0\\\" fontsize=10];\\n  ft_Add [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Add\\n(ft_Add)\\\" fontsize=10];\\n  X -> ft_Add;\\n  ft_Ad_Addcst -> ft_Add;\\n  ft_Add -> ft_Ad_C0;\\n\\n  ft_y [shape=box label=\\\"ft_y\\\" fontsize=10];\\n  ft_Log [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Log\\n(ft_Log)\\\" fontsize=10];\\n  ft_Ad_C0 -> ft_Log;\\n  ft_Log -> ft_y;\\n\\n  variable1 [shape=box label=\\\"variable1\\\" fontsize=10];\\n  Scaler [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Scaler\\n(Scaler)\\noffset=[1.90850727 1.38475007 1...\\nscale=[8.81710483 9.29834823 2....\\\" fontsize=10];\\n  ft_y -> Scaler;\\n  Scaler -> variable1;\\n\\n  label [shape=box label=\\\"label\\\" fontsize=10];\\n  probability_tensor [shape=box label=\\\"probability_tensor\\\" fontsize=10];\\n  LinearClassifier [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"LinearClassifier\\n(LinearClassifier)\\nclasslabels_ints=[0 1 2]\\ncoefficients=[-0.96547866  0.95...\\nintercepts=[ 0.1182096  2.11837...\\nmulti_class=1\\npost_transform=b'SOFTMAX'\\\" fontsize=10];\\n  variable1 -> LinearClassifier;\\n  LinearClassifier -> label;\\n  LinearClassifier -> probability_tensor;\\n\\n  probabilities [shape=box label=\\\"probabilities\\\" fontsize=10];\\n  Normalizer [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Normalizer\\n(Normalizer)\\nnorm=b'L1'\\\" fontsize=10];\\n  probability_tensor -> Normalizer;\\n  Normalizer -> probabilities;\\n\\n  Cast [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"Cast\\n(Cast)\\nto=7\\\" fontsize=10];\\n  label -> Cast;\\n  Cast -> output_label;\\n\\n  ZipMap [shape=box style=\\\"filled,rounded\\\" color=orange label=\\\"ZipMap\\n(ZipMap)\\nclasslabels_int64s=[0 1 2]\\\" fontsize=10];\\n  probabilities -> ZipMap;\\n  ZipMap -> output_probability;\\n}\");\n",
              "document.getElementById('Mb07a422654ee4a4897d015c087ce35a7').innerHTML = svgGraph; });\n",
              "\n",
              "</script>"
            ],
            "text/plain": [
              "<jyquickhelper.jspy.render_nb_js_dot.RenderJsDot at 0x1b320632c70>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "onx = to_onnx(pipe, X_train.astype(numpy.float64), rewrite_ops=True)\n",
        "%onnxview onx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's compare the time to *numpy*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.68 \u00b5s \u00b1 156 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n"
          ]
        }
      ],
      "source": [
        "def custom_numpy_fct(x):\n",
        "    return numpy.log(x + numpy.float64(1))\n",
        "\n",
        "%timeit custom_numpy_fct(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18.3 \u00b5s \u00b1 878 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit custom_fct(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}